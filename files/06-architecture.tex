%!TEX root=/home/ska124/Dropbox/Thesis/thes-full.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%     Chapter 3   
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Amoeba Cache Architecture}
\label{chap:ac_architecture}

As described in Section \ref{sec:cache_memory_systems}, a conventional cache organises the data array into a 2 dimensional structure. A transparently addressed cache uses the same namespace (memory address space layout) as the main memory. The blocks which are stored in the sets are \textit{tagged} with the aligned start address of block present in the main memory. The \textit{tags} for the cache blocks currently present in the cache set are maintained in a separate array. When a search is being performed to find out whether a required physical address is present in the cache, the tag array is looked up to determine a cache hit or a cache miss. The organization of the cache set and tag array is shown in Figure \ref{fig:set_assoc_arch}. The effective address is the virtual address supplied by the CPU of the required datum. The component bits of the effective address is segmented into 3 parts which form the \textit{Virtual Page Number(VPN)}, set number and byte offset. The set number and byte offset are looked up in the tag array while the VPN is looked up in the \textit{Translation Lookaside Buffer(TLB)} to check that the current process has brought in the corresponding page and it is valid. The organisation described (and shown in Fig \ref{fig:set_assoc_arch}) is virtually indexed, physically tagged organisation where the lookup logic does not include the TLB translation in the critical path to enable faster searches. There are other organisations such as virtually indexed, virtually tagged and physically indexed, physically tagged which are uncommon due to inherent issues with their design. The tradeoff for a virtually indexed, physically tagged cache is that it can only grow in size with an increase in the associativity of each set, or an increase in the size of each cache block. The Intel Sandy Bridge architecture is known to use a virtually indexed, physically tagged cache organisation.



\begin{figure}[b]
  %% Pg 84 - Jacob
  \begin{center}
    \includegraphics[width=\textwidth]{files/Figures/06-NWaySetAssocCache.pdf}
    \caption[Conventional N-Way Set-Associative Cache]{\textbf{Conventional N-Way Set-Associative Cache} \bigspot{1} The Virtual Page Number (VPN) is used to look up the entry in the Translation Lookaside Buffer (TLB) \bigspot{2} According to the number of sets in the cache, the following bits from the address are used to look up the corresponding set from the cache \bigspot{3} The tags read out from the set are compared with the translation from the TLB and tested for equality \bigspot{4} The corresponding cache block is forwarded to the output buffer for the tag which matches the TLB lookup \bigspot{5} Using the byte offset from the CPU, the mutiplexer selects the correponding critical word }
    \label{fig:set_assoc_arch}
  \end{center}
\end{figure}

\clearpage

In contrast to a conventional cache, the \AC\ architecture enables the memory hierarchy to fetch and allocate space for a range of words (i.e. a variable granularity cache block) based on the spatial locality of the application. For example, consider a 64K cache (256 sets) that allocates 256 bytes per set. These 256 bytes can adapt to support, for example, eight 32-bytes blocks, thirty-two 8-byte blocks, or four 32-byte blocks and sixteen 8-byte blocks, based on the set of contiguous words likely to be accessed. 
\\ \\
The key challenges to realising the \AC\ architecture are
\begin{enumerate}[noitemsep]
	\item To support a variable number of blocks per set
	\item To support a variable granularity for each block
	\item To support a variable number of tags, which correspond to the blocks in the set
\end{enumerate}

\begin{figure}[h]
  %% Pg 84 - Jacob
  \begin{center}
    \includegraphics[width=\textwidth]{files/Figures/06-AmoebaCacheArch.pdf}
    \caption[Amoeba Cache Overview]{\textbf{Amoeba Cache Overview} The static RAM (SRAM) array where the tags and data are colocated is shown on the right. The \code{T? Bitmap} and the \code{V? Bitmap} for the \AC\ are shown on the left. Each block in the SRAM array represents 8 bytes (1 word). In this specific example, we show an \AC\ with 4 sets and 1024 bytes per set. The invalid, data and tag words (marked in the SRAM array) are tracked by setting the corresponding bits in the \code{T? and V? Bitmaps}. This information is maintained in order to simplify cache operations such as insertion and refill. }
    \label{fig:amoeba_cache_arch}
  \end{center}
\end{figure}

The \AC\ adopts a solution inspired by software data structures, where programs hold meta-data and actual data entries in the same address space. To achieve maximum flexibility, the \AC\ completely eliminates the tag array and collocates the tags with the actual data blocks (see Figure~\ref{fig:amoeba_cache_arch}). To distinguish which words are data words and which ones are tags within the set, we use a bitmap data structure (labeled \code{T? Bitmap} in Fig~\ref{fig:amoeba_cache_arch}). For each word in the set which is a tag, we set the corresponding bit in the \code{T? Bitmap}. We also decouple the conventional valid/invalid bits (typically associated with the tags) and organize them into a separate array (labeled \code{V? Bitmap} in Fig~\ref{fig:amoeba_cache_arch}) to simplify block replacement and insertion. \AC\ tags are composed of a \code{Region Tag} and a tuple which consists of the \code{Start} and \code{End} address of the variable granularity cache block. The data block immediately follows the tag word as shown in Fig~\ref{fig:amoeba_cache_arch}. The following sections provide more detail about the \AC\ architecture and how cache operations are performed.


\section{Amoeba Blocks and Set-Indexing}


\begin{figure}[h]
  %% Get images from http://en.wikipedia.org/wiki/CPU_cache#Associativity
  \subfloat[Memory Regions]{
    \includegraphics[width=0.5\textwidth]{files/Figures/06-MemoryRegions.pdf}
  }
  \subfloat[Addressing]{
     \includegraphics[width=0.5\textwidth]{files/Figures/06-Addressing.pdf}
  }
  \caption[Memory Regions]{ (a) The linear memory address space is segmented into Regions. The \AB{}s are constrainted to have their start and end within a single memory region. (b) 64 bits are used to encode the Region Tag, the Set Index, the start or end word and the word offset in the tag for an \AB{}.  }
  \label{fig:mem_region_addr}
\end{figure}


The \AC\ data array holds a collection of varied granularity \AB{}s that do not overlap. Each \AB\ is a 4 tuple consisting of \code{\textless RegionTag, Start, End, Data-Block\textgreater} (Figure~\ref{fig:amoeba_cache_arch}). The first 3 components of the tuple are equivalent to a tag in a conventional cache. We allocate 8 bytes (1 word) for each tag. In order to simplify cache lookups for \AB{}s, we partition the address space into \code{Regions}. A \code{Region} is an aligned block of memory of size \code{RMAX} bytes. The boundaries of any \AB{} block (\code{Start} and \code{End}) are constrained to lie within the regions' boundaries. The minimum granularity of the data in an \AB\ is 1 word and the maximum is \code{RMAX} words. We can encode \code{Start} and \code{End} in $log_2(RMAX)$ bits. The set indexing function masks the lower $log_2(RMAX)$ bits to ensure that all \AB{}s (every memory word) from a region index to the same set. The Region Tag and Set-Index are identical for every word in the \AB{}. Retaining the notion of \textit{sets} enables fast lookups and helps elude challenges such as synonyms (same memory word mapping to different sets). When comparing against a conventional cache, we set \code{RMAX} to 8 words (64 bytes), ensuring that the set indexing function is identical to that in the conventional cache to allow for a fair evaluation.



\section{Data Lookup}

When data is referenced by the CPU, a cache lookup takes place in order to determine whether the required datum is present in the cache or not (resulting in a cache hit or miss). The operation percolates down the memory hierarchy until a cache returns a hit or the backing store supplies the datum required. Fig~\ref{fig:set_assoc_arch} shows a conventional cache which operates in \textit{Fast Mode}, where the contents of the entire set is read out into the output buffer in parallel with the tag lookup. Megabyte sized caches, with larger sets, may want to avoid the extra cost of reading out all ways to the output buffer and wait until the tag lookup completes to read out only the correct way from the set. Though this saves energy, it serializes the lookup and takes longer. The delay is usually tolerated as the \textit{Serial Mode} lookup is often implemented in the L2 caches or lower in the memory heirarchy. Another approach which minimises energy whilst still reading out the way in parallel is \textit{way prediction}\cite{patent:DataCacheWayPrediction,patent:WayPredictionVirtualHint}, commonly used in processors manufactured by MIPS.
\\

In contrast to a conventional cache, the \AC\ needs to lookup tags from the SRAM array to determine a hit or miss. The metadata stored in the \code{T? Bitmap} is used during the lookup operation in the \AC{}. Figure~\ref{fig:ac_lookup} describes the steps of the lookup procedure in an \AC{}. The overheads incurred due to the extra stages introduced in the critical path are evaluated in chapter \ref{sec:hardware_complexity}.


\begin{figure}[h]
  \includegraphics[width=\textwidth]{files/Figures/06-Lookup.pdf}
  \caption[Amoeba Cache Lookup]{\textbf{Amoeba Cache Lookup} : The incoming effective address is segmented into the region tag, set index and word offset. \bigspot{1} The \code{Tag? Bitmap} is looked up to determine which words in the activated set are required for the tag comparison. Note that given the minimum size of a \AB{} is two words (1 word for the tag metadata, 1 word for the data), adjacent words cannot be tags. Given this constraint, 
  the number of 2-1 multiplexers required to route one of the adjacent words to the comparator ($\in$ operator), is equal to half the number of words in the set. \bigspot{2} Simultaneously, the set is activated and the contents are latched onto the output buffer. \bigspot{3} The appropriate tag words are selected with the input from the the \code{Tag? Bitmap}. \bigspot{4} The comparator generates the hit signal for the word selector. The $\in$ operator consists of two comparators: a) an aligned \code{Region tag} comparator, a conventional $==$ (64 - $log_2N_{sets}$ - $log_2{RMAX}$ bits wide, e.g., 50 bits) that checks if the \AB{} belongs to the same region and b) a $ Start <= W < END $ range comparator ($log_2RMAX$ bits wide; e.g., 3 bits) that checks if the \AB\ holds the required word. Finally, in \bigspot{5}, the tag match activates and selects the appropriate word. The critical path (as indicated on the left) includes the read out from the set, the tag selectors and the $\in$ operation.}
  \label{fig:ac_lookup}
\end{figure}

\clearpage

\section{Block Insertion}

On a miss for the desired word, a spatial granularity predictor is invoked (see Section~\ref{sec:spatial_pattern_predictor}), which specifies the range of the \AB{} to refill. To determine a position in the set to slot the incoming block we can leverage the \code{Valid? Bitmap}. The \code{V? Bitmap} has 1 bit/word in the cache; a ``1'' bit indicates the word has been allocated (valid data or a tag). To find space for an incoming data block we perform a substring search on the \code{V? Bitmap} of the cache set for contiguous 0s (empty words). For example, to insert an \AB{} of five words (four words for data and one word for tag), we perform a substring search for \textit{00000} in the \code{V? Bitmap} / set (e.g., 32 bits wide for a 64K cache). If we cannot find the space, we keep triggering the replacement algorithm until we create the requisite contiguous space. Following this, the \AB\ tuple (Tag and Data block) is inserted, and the corresponding bits in the \code{T? and V? Bitmaps} are set. The 0s substring search can be accomplished with a lookup table; many current processors already include a substring instruction. Intel SSE 4.2 include the instruction, \code{PCMPISTRI}, which can accomplish the required task.

\section{Replacement Policy}

The replacement policy of a cache determines which blocks are evicted when new data is brought in and there is no room to store it. The replacement algorithm tries to make an optimal choice where it evicts a blocks which is not expected to be used in the near future. The most optimal choice possible would be to remove a block which is not going to be referenced in the program again or which is going to be referenced farthest in the future in comparison to the other cache blocks. The optimal algorithm is also known as \textit{"Belady's Optimal Algorithm"}, named after Hungarian computer scientist, Laszlo Belady.
\\

The Least Recently Used (LRU) algorithm is a popular choice for conventional caches and is based on the principle of temporal locality of reference. The hardware tracks data reference to the different cache blocks and when a new insertion request arrives, the least recently used block in the set is evicted. Implementing an LRU cache in software is relatively easy with the use of a linked list however, in hardware requires a large amount of resources. Thus hardware manufactureres commonly implement the \textit{Pseudo-LRU}(PLRU) which has a lower metadata overhead and is a reasonable approximation of LRU. The tree based PLRU was implemented in processors such as the Intel 80486 and many processors in the PowerPC family. 

\subsection{\AC\ Replacement Policy}

To reclaim the space from an \AB\, the tag bits T? (tag) and V? (valid) bits corresponding to the block are unset. The key issue is identifying the \AB\ to replace. Classical pseudo-LRU algorithms~\cite{Kedzierski-ipdps-2010,manual:OpenSparcT1} keep the metadata for the replacement algorithm separate from the tags to reduce port contention. To be compatible with pseudo-LRU and other algorithms such as DIP~\cite{qureshi-isca-2007} that work with a fixed \# of ways, we can logically partition a set in \AC\ into $N_{ways}$. For instance, if we partition a 32 word cache set into 4 logical ways, any access to an \AB\ tag found in words 0 ---7 of the set is treated as an access to logical way 0. Finding a replacement candidate involves identifying the selected replacement way and then picking (possibly randomly) a candidate \AB{}. 

\subsection{Other Replacement Policies}

More refined replacement algorithms that require per-tag metadata can harvest the space in the tag-word of the \AB\, which is 64 bits wide (for alignment purposes) while physical addresses rarely extend beyond 48 bits.


% \subsection{Partial Misses} \label{sec:partialmiss} 

% With variable granularity data blocks, a challenging although rare case (5
% in every 1K accesses) that occurs is a \textit{partial miss}. It is observed
% primarily when the spatial locality changes.  Figure~\ref{fig:partial-miss}
% shows an example. Initially, the set contains two blocks from a region R, one
% \AB\ caches words 1 --3 (Region:R, START:1 END:3) and the other holds words 5
% --6 (Region:R START:5 END:6). The CPU reads word 4, which
% misses, and the spatial predictor requests an \AB\ with range START:0 and
% END:7. The cache has \AB{}s that hold subparts of the incoming \AB{}, and some
% words (0, 4, and 7) need to be fetched.

% \AC\ removes the overlapping sub-blocks and allocates a new \AB{}. This is a
% multiple step process:\spot{1} On a miss, the cache identifies the overlapping
% sub-blocks in the cache using the tags read out during lookup. $\cap \neq
% NULL$ is true if $START_{new}$ < $END_{Tag}$ and $END_{new}$ > $START_{Tag}$
% ($New=$ incoming block and $Tag=$ \AB\ in set).  \spot{2} The data blocks that
% overlap with the miss range are evicted and moved one-at-a-time to the MSHR
% entry. \spot{3} Space is then allocated for the new block, i.e.,
% it is treated like a new insertion. \spot{4} A miss request is issued for the
% entire block (START:0 --- END:7) even if only some words (e.g., 0, 4, and 7)
% may be needed. This ensures request processing is simple and only a single
% refill request is sent.\spot{5} Finally, the incoming data block is patched
% into the MSHR; only the words not obtained from the L1 are copied (since the
% lower level could be stale).


% \begin{figure}[!h]
% \centering
% \includegraphics[width=0.37\textwidth]{figures/PartialMiss}
% \begin{minipage}[b]{0.5\textwidth} 
% { 
% \centering \spot{1}
%     Identify blocks overlapping with \code{New} block. \spot{2}
%     Evict overlapping blocks to MSHR. \spot{3} Allocate space
%     for new block (treat it like a new insertion). \spot{4} Issue
%     refill request to lower level for entire block. \spot{5} Patch
%     only newer words as lower-level data could be stale.  
% %(e.g., writeback cache)
% }
% \end{minipage}
% \caption{Partial Miss Handling. Upper: Identify relevant
%   sub-blocks. Useful for other cache controller events as well, e.g.,
%   recalls. Lower: Refill of words and insertion.}
% \label{fig:partial-miss}
% \end{figure}

\section{Spatial Pattern Predictor}
\label{sec:spatial_pattern_predictor}

\section{Related Work}
\subsection{Line Distillation}
\subsection{Sector Caches}
\subsection{Indexed Indirect Caches}
\subsection{Cache Compression}
